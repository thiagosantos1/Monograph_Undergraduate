\chapter{Conclusão}
\label{cap:conclusão}

 
Embora eu tenha entrado com o trabalho já em andamento, eu participei de alguma forma de todas as etapas do projeto. Na fase inicial, buscamos identificar a melhor forma de processar e representar os dados de entrada(Newick, PUTs e Traits) . Sendo assim, construímos uma estrutura orientada a objeto, com a maior organização possível. Sendo assim, ao criar um Kernel, não seria necessário passar diversos parâmetros e dados, apenas o ponteiro para uma estrutura. Isso nos permitiu, junto a algoritmos altamente paralelos, utilizar bastante da potência da computação em GPU.

Para criar a estrutura orientada a objeto, criamos uma função Parse, a qual é responsável por receber todos os dados de entrada(Newick, PUTs e Traits) e os transformar em dados processados, armazenados em seus devidos vetores. O algoritmo foi realizado de forma sequencial, pois o mesmo requer muitas dependências e tomadas de decisão, o que não favorece um algoritmo paralelo, podendo inclusive ter resultados inferiores ao sequencial.

Após a execução do Parse, toda a estrutura e montada e organizada, favorecendo assim a execução das próximas etapas (Inserir Espécies e Matriz de Distância), as quais eu não tive uma participação direta, apenas o aluno Evandro. 

Para a criação do I de Moran, utilizamos de forma considerável a concorrência na execução de tarefas, podendo chegar a ter milhões de threads em execução simultânea. Na criação do Kernel, é lançado um bloco por árvore e cada bloco possui tantas threads quanto forem o número de espécies, assim cada bloco é responsável por calcular o I de Moran daquela árvore em específico. Para o cálculo, utilizamos o acesso rápido a memória compartilhada para armazenar informações sobre classes de distância e variáveis de soma. Como o I de Moran é dividido por classe de distância, essa informação são consultadas constantemente por cada thread, garantindo então o acesso instantâneo, o que gera um impacto positivo no desempenho do algoritmo. Para calcular o índice de correção espacial, cada thread fica responsável por calcular uma faixa de valores na matriz de distância, o que pode gerar uma alta concorrência pelos dados. Sendo assim, embora possa desfavorecer um pouco o desempenho em geral do algoritmo, teve a necessidade do uso de operações atômicas e barreiras de sincronização. 
 
Apresentamos algumas possibilidades e soluções de melhorias, as quais foram possíveis graças ao uso da computação em GPU. Foi possível então alcançar um elevado speedup se comparado a versão seriais, graças ao uso da computação paralela baseado em GPU, aliado a uma boa estrutura orientada a objeto e bem planejada para a arquitetura. Com a base desse projeto, é possível avançar muito mais, criando diversos outros métodos estatísticos que requerem a matriz de distância patrística como entrada, o I de Moran foi apenas um dos vários que é possível ser calculado. 
